{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "f76cc1eb829b45cca69074bdb6eaaad9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2318,
    "execution_start": 1711111835496,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Basics \n",
    "import pandas as pd\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "from collections import Counter\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Prediction Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "# Suffix \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate, Reshape, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#Evaluation\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#Encoders & scalers \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "f05a3de05c9243f7abb225ecf2ab986a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 91,
    "execution_start": 1711109279138,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "log = xes_importer.apply('Road_Traffic_Fine_Management_Process.xes')\n",
    "df = log_converter.apply(log, variant=log_converter.Variants.TO_DATA_FRAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "1d22ff987f5a4d5da2433ff9893d1c36",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2377,
    "execution_start": 1711111839724,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# path = \"pm_roads_data.csv\"\n",
    "# df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "46605989f54043558110d14d87066c76",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": []
   },
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e463add032b64b80b552d5a11755d047",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**Data Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "3c73e1febffa44c4928ad31b3577e7e3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 4503,
    "execution_start": 1711109280359,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "traces = df.groupby('case:concept:name')['concept:name'].apply(list).tolist() # Make a list of all sequences\n",
    "max_length = df['case:concept:name'].value_counts().max() # Find the longest sequence of events in the dataset\n",
    "cumulative_counts = df.groupby('case:concept:name').cumcount() # Stores the position in a sequence of each row in the DF\n",
    "df['time:timestamp'] = pd.to_datetime(df['time:timestamp']) # Converts the timestamp column to datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b02bbab883254c4bbb1ba69c38e4897a",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**Event Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "f805810697544b23afed766648c3169b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 375,
    "execution_start": 1711109284902,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "most_common_events = [] # List storing the most common events for each position\n",
    "for i in range(max_length):\n",
    "    all_events_at_i = [trace[i] for trace in traces if len(trace) > i] # All events occurring at position i\n",
    "    counts = Counter(all_events_at_i) # The respective counts per type of event \n",
    "    most_common_event = counts.most_common(1)[0][0] # Find the most common event at that position\n",
    "    most_common_events.append(most_common_event) # Store the most common event in the list\n",
    "    \n",
    "most_common_events = most_common_events[1:] # Since we will be predicting only the next event, never the first\n",
    "most_common_events.append(\"No next\")  # Since after the last event in the longest trace, there is no next one "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d61d820845fa4d3a941d35ffb7fa5e9e",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**Time Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "393b2444848e409b9a555d2131ba51e8",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 11057,
    "execution_start": 1711109285287,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "times = df.groupby('case:concept:name')['time:timestamp'].apply(list).tolist() # A list of the timestamps of all sequences\n",
    "\n",
    "average_times = []\n",
    "for i in range(0, max_length - 1):\n",
    "    all_times_at_i = [time[i+1] - time[i] for time in times if len(time) > i+1] # All time differences occuring at i\n",
    "    total_seconds = sum(time.total_seconds() for time in all_times_at_i) # In seconds, otherwise overflow\n",
    "    average_time = total_seconds / len(all_times_at_i) # Calculate the average for each position\n",
    "    average_time = timedelta(seconds=average_time) # Revert to time objectcs\n",
    "    average_times.append(average_time)\n",
    "    \n",
    "average_times.append(timedelta()) # Since no event will occur after the last event in the longest trace "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "95585c5eedc144ab9b0752bf1a18ec3e",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**Add the predictions to the dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "e6df8517fe434cf9a47e817c48591c0d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5615,
    "execution_start": 1711109296363,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Baseline results\n",
    "df[\"baseline_next_event\"] = [most_common_events[i] for i in cumulative_counts] # Next event prediction\n",
    "df[\"baseline_time_to_next\"] = [average_times[i] for i in cumulative_counts] # Time to next event prediction\n",
    "df[\"baseline_time_of_next\"] = df[\"time:timestamp\"] + df[\"baseline_time_to_next\"] # Time of next event prediction\n",
    "df[\"baseline_time_of_next\"] = df[\"baseline_time_of_next\"].dt.strftime('%Y-%m-%d %H:%M:%S+00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "40ab43d658664c89b7efb808fc4d3e3b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "**Evaluation of baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "3ed55f1eb8d049a8b8bcfd2323ccbe5d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9100,
    "execution_start": 1711109301986,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Evaluation:\n",
      "Time, MSE: 18512.763453078525\n",
      "Time, RMSE: 136.06161638419016\n",
      "Time, MAE: 75.65790514185976\n",
      "Events, F1 average: 0.6694420597301748\n",
      "Events, Accuracy: 0.5723048426451992\n"
     ]
    }
   ],
   "source": [
    "df_eval = df.copy()\n",
    "df_eval['days_to_next'] = df_eval.groupby('case:concept:name')[\"time:timestamp\"].shift(-1) - df_eval[\"time:timestamp\"]\n",
    "df_eval['days_to_next'] = df_eval['days_to_next'].dt.days \n",
    "df_eval['days_to_next'].fillna(0, inplace = True) \n",
    "df_eval['predicted_days'] = df_eval['baseline_time_to_next'].dt.days\n",
    "\n",
    "df_eval['next_event'] = df_eval.groupby('case:concept:name')['concept:name'].shift(-1)\n",
    "df_eval['next_event'].fillna('No next', inplace = True)\n",
    "\n",
    "mse = mean_squared_error(df_eval['predicted_days'], df_eval['days_to_next'])\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(df_eval['predicted_days'], df_eval['days_to_next'])\n",
    "f1 = f1_score(df_eval['baseline_next_event'], df_eval['next_event'], average='weighted')\n",
    "\n",
    "accuracy = accuracy_score(df_eval['baseline_next_event'], df_eval['next_event'])\n",
    "print('Baseline Evaluation:')\n",
    "print('Time, MSE:', mse)\n",
    "print('Time, RMSE:', rmse)\n",
    "print('Time, MAE:', mae)\n",
    "print('Events, F1 average:', f1)\n",
    "print('Events, Accuracy:', accuracy)\n",
    "del(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "fa093d42a51d4a1a9bd46e5603ea7cfa",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 85,
    "execution_start": 1711111824643,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# The following objects are no longer used after implementing the baseline and deleting them frees up memory \n",
    "del(traces)\n",
    "del(times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "971b2f23313c40e78969be923e870423",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": []
   },
   "source": [
    "# Train/Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "a47ac8485159479c88a50470a5cb7f4e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 935,
    "execution_start": 1711111904033,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "df_model = df.copy() \n",
    "df_model['time:timestamp'] = pd.to_datetime(df_model['time:timestamp'])\n",
    "\n",
    "# Preparing for split\n",
    "threshold = pd.Timestamp('2009-07-31 00:00:00', tz='UTC') # Set a cut-off timestamp (vertical line)\n",
    "before_threshold = df_model[df_model['time:timestamp'] < threshold]['case:concept:name'].unique() # Traces that have events before cut-off\n",
    "after_threshold = df_model[df_model['time:timestamp'] >= threshold]['case:concept:name'].unique() # Traces that have events at/after cut-off\n",
    "mixed_case_ids = set(before_threshold) & set(after_threshold) # Traces that have both "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "4dafc9f13fcb4aa1afdf2f4c294a2872",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 475,
    "execution_start": 1711111926418,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode\n",
    "encoder = LabelEncoder() \n",
    "events = df['concept:name'].unique()\n",
    "events = np.append(events, ['No next', '<SOS>', '<EOS>'])\n",
    "events\n",
    "encoder.fit(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Engineering**\n",
    "Note: the features \"dismissal_encoded\" and \"in_debt\" are specific to the RTFM dataset. If running the tool on a different dataset, they can be replaced with other Boolean features or removed. To remove: comment out the part of the code specified in the cell below, remove them as names from the list \"features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are going to need this again, so make it into a function: \n",
    "def addFeatures(df_model):\n",
    "    df_model['time:timestamp'] = pd.to_datetime(df_model['time:timestamp']) # Converts the timestamp column to datetime\n",
    "    \n",
    "    #The position of an event in a trace\n",
    "    df_model['position'] = df_model.groupby('case:concept:name').cumcount() # The position of an event in a trace\n",
    "\n",
    "    #The days that will pass until the next event as integers\n",
    "    df_model['days_to_next'] = df_model.groupby('case:concept:name')['time:timestamp'].shift(-1) - df_model['time:timestamp']\n",
    "    df_model['days_to_next'] = df_model['days_to_next'].dt.days # Turns timedelta objects into ints for prediction models\n",
    "    df_model['days_to_next'].fillna(0, inplace = True)\n",
    "    df_model['days_to_next'] = df_model['days_to_next'].astype(int)\n",
    "\n",
    "    #The days that have passed since the last event as integers \n",
    "    df_model['days_since_last'] = df_model['time:timestamp'] - df_model.groupby('case:concept:name')['time:timestamp'].shift(1)\n",
    "    df_model['days_since_last'].fillna(pd.Timedelta(days=0), inplace = True)\n",
    "    df_model['days_since_last'] = df_model['days_since_last'].dt.days \n",
    "\n",
    "    #The current day of the week\n",
    "    df_model['weekday'] = df_model['time:timestamp'].dt.dayofweek / 7 \n",
    "\n",
    "    #The days that have passed since the start of the trace\n",
    "    df_model['days_since_start'] = df_model.groupby('case:concept:name')['days_since_last'].cumsum()\n",
    "\n",
    "    #The type of the next event that will occur\n",
    "    df_model['next_event'] = df_model.groupby('case:concept:name')['concept:name'].shift(-1)\n",
    "    df_model['next_event'].fillna('No next', inplace = True)\n",
    "    \n",
    "    df_model['next_event'] = encoder.transform(df_model['next_event'])\n",
    "    df_model['type_of_event'] = encoder.transform(df_model['concept:name'])\n",
    "\n",
    "    #DATASET SPECIFIC FEATURES BELOW! If running on a different dataset, comment out the following lines.\n",
    "    \n",
    "    #Whether a fine has been dismissed by judge or prefecture appeal \n",
    "    dismissal1 = (df_model['dismissal'] == 'G') | (df_model['dismissal'] == '#')\n",
    "    df_model['dismissal_encoded'] = 0 \n",
    "    df_model.loc[dismissal1, 'dismissal_encoded'] = 1\n",
    "\n",
    "    #Whether the person still has some amount to pay\n",
    "    df_model['debt'] = df_model['amount'].fillna(0) + df_model['expense'].fillna(0) \n",
    "    df_model['debt'] = df_model.groupby('case:concept:name')['debt'].cumsum()\n",
    "    in_debt = (df_model['totalPaymentAmount'].fillna(0) >= df_model['debt'])\n",
    "    df_model['in_debt'] = 1 #1 if yes\n",
    "    df_model.loc[in_debt, 'in_debt'] = 0 #0 if fine is completely paid and the case can be closed  \n",
    "    \n",
    "    return df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "fbed8af15b3548d1801a94071d147e76",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 872,
    "execution_start": 1711111918145,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "df_model = addFeatures(df_model) \n",
    "\n",
    "# Note: 'dismissal_encoded' and 'in_debt' are NOT general features, remove if NOT using the RFTM dataset\n",
    "event_features = ['position', 'type_of_event', 'days_since_last', 'days_since_start', 'dismissal_encoded', 'in_debt']\n",
    "time_features = ['position', 'type_of_event', 'days_since_last', 'dismissal_encoded']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f8fe19c8807747509d065f0c8fb0e347",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": []
   },
   "source": [
    "**Splitting** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "4adbb7c7b7944b1984c22ac50570d029",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 219,
    "execution_start": 1711111933190,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "df_train = df_model[(~df_model['case:concept:name'].isin(mixed_case_ids)) & (df_model['case:concept:name'].isin(before_threshold))]\n",
    "df_test = df_model[(~df_model['case:concept:name'].isin(mixed_case_ids)) & (df_model['case:concept:name'].isin(after_threshold))]\n",
    "del(df_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale based on train data to (hopefully) cover the problem of train traces spanning over longer periods \n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_train['days_since_start'] = scaler.fit_transform(np.array(df_train['days_since_start']).reshape(-1,1)) \n",
    "df_train['days_since_last'] = scaler.transform(np.array(df_train['days_since_last']).reshape(-1,1)) \n",
    "\n",
    "df_test['days_since_last'] = scaler.transform(np.array(df_test['days_since_last']).reshape(-1,1)) \n",
    "df_test['days_since_start'] = scaler.transform(np.array(df_test['days_since_start']).reshape(-1,1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning incomplete traces from train data (RTFM specific)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean traces that end in 'Send Fine' \n",
    "last = df_train.groupby(\"case:concept:name\").tail(1)\n",
    "traces_to_clean = last[last[\"concept:name\"] == \"Send Fine\"][\"case:concept:name\"].unique()\n",
    "df_train = df_train[~df_train['case:concept:name'].isin(traces_to_clean)]\n",
    "#Note that we only do the cleaning on the train data, as filtering the test data would be unrealistic in a real-life situation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6dcefb324a1b41d9b27d444ffb12e049",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": []
   },
   "source": [
    "# Training Models (events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": "f9daab861a3f4572ac8bd9b21c8badd2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 18,
    "execution_start": 1711109313097,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "X_train_events = df_train[event_features]\n",
    "y_train_events = df_train['next_event']\n",
    "\n",
    "X_test_events = df_test[event_features]\n",
    "y_test_events = df_test['next_event']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": "ef3a800e4cc34dbdb22b9754aa479047",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21197,
    "execution_start": 1711109313102,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_events,y_train_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ec4b081419774f73a4202a4c77473915",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": []
   },
   "source": [
    "# Training Models (time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": "d29540aafbad48ebb6e7f44fb3beecd4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 245,
    "execution_start": 1711109334326,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "x_train_time = df_train[time_features]\n",
    "y_train_time = df_train['days_to_next']\n",
    "\n",
    "x_test_time = df_test[time_features]\n",
    "y_test_time = df_test['days_to_next']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": "a74f66790d744d2cbce49dc81ba88116",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1092,
    "execution_start": 1711109334330,
    "scrolled": true,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_reg = xgb.XGBRegressor(objective ='reg:squarederror', random_state=42, max_depth = 4)\n",
    "xgb_reg.fit(x_train_time, y_train_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7bca06ab0c79422195832b4410779be6",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Evaluation of random forest on events prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cell_id": "30a59755eaa8466694ec0ce62bb1c681",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1984,
    "execution_start": 1711109348030,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Evaluation:\n",
      "Events, F1 average: 0.7314757752339297\n",
      "Events, Accuracy: 0.7834345274235984\n"
     ]
    }
   ],
   "source": [
    "# event_prediction = rf.predict(X_test_events)\n",
    "# f1 = f1_score(y_test_events, event_prediction, average='weighted')\n",
    "# accuracy = accuracy_score(y_test_events, event_prediction) \n",
    "\n",
    "# df_eval = df_test.copy()\n",
    "# df_eval['predicted_next'] = encoder.inverse_transform(event_prediction)\n",
    "# df_eval['next_event'] = encoder.inverse_transform(df_eval['next_event'])\n",
    "# classes = df_eval['next_event'].unique()\n",
    "\n",
    "# print('Random Forest Evaluation:')\n",
    "# print('Events, F1 average:', f1)\n",
    "# print('Events, Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "107a4a4ac7dd43e0bd74ce188d89a27d",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Evaluation of xgb on time to next event prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "cell_id": "43e273409ef0432fa40eb37a53ab7297",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 116,
    "execution_start": 1711109350057,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Evaluation:\n",
      "Time, MSE: 7407.458757046154\n",
      "Time, RMSE: 86.0665948963136\n",
      "Time, MAE: 38.99964583468667\n"
     ]
    }
   ],
   "source": [
    "# time_prediction = xgb_reg.predict(x_test_time)\n",
    "# mse = mean_squared_error(y_test_time, time_prediction)\n",
    "# rmse = np.sqrt(mse)\n",
    "# mae = mean_absolute_error(y_test_time, time_prediction)\n",
    "\n",
    "# print('XGB Evaluation:')\n",
    "# print('Time, MSE:', mse)\n",
    "# print('Time, RMSE:', rmse)\n",
    "# print('Time, MAE:', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f24164f14e8941959bfa0624a16a0ecd",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": []
   },
   "source": [
    "# Predict on entire dataset to export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": "732a2fdfbd0b401890ba580647c8a8a4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 927,
    "execution_start": 1711109335441,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "df_predict = df.copy()\n",
    "df_predict = addFeatures(df_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": "db58dcb80e5f4956924bf4fbda3a5c8e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10056,
    "execution_start": 1711109336379,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "rf_prediction = rf.predict(df_predict[event_features])\n",
    "xgb_prediction = xgb_reg.predict(df_predict[time_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": "147dc5a5c2be49579c59453a8a9082cb",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1430,
    "execution_start": 1711109346478,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "xgb_prediction = [int(i) for i in xgb_prediction] # Prediction is continious, round down to whole days \n",
    "days = pd.to_timedelta(xgb_prediction, unit='D')  # Make them timedelta objects, so we can sum with timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": "414d147748f641779263157f62c46649",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 59,
    "execution_start": 1711109347912,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "df['rf_next_event'] = encoder.inverse_transform(rf_prediction) # Decode the encoding of the event prediction back into strings\n",
    "df['xgb_time_of_next'] = df['time:timestamp'] + days # Get the predicted time of next event "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ff8804e7a2fb481a95fd42642de4c017",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": []
   },
   "source": [
    "# Suffix Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "7053e64af2794d49ae2f235d6e026ce6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 281,
    "execution_start": 1711111943026,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(sparse_output=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse_output=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(sparse_output=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 8 # the maximum trace length on which the model will be trained is max_length - 2\n",
    "no_next = encoder.transform(['No next'])[0]\n",
    "sos = encoder.transform(['<SOS>'])[0]\n",
    "eos = encoder.transform(['<EOS>'])[0]\n",
    "\n",
    "group_counts = df.groupby('case:concept:name').size()\n",
    "groups_to_clean = group_counts[(group_counts > max_length - 2)].index \n",
    "\n",
    "df_lstm_train = df_train[~df_train['case:concept:name'].isin(groups_to_clean)]\n",
    "df_lstm_test = df_test\n",
    "\n",
    "df_lstm_train = df_lstm_train[[\"case:concept:name\",\"type_of_event\", \"days_since_last\", \"days_since_start\", \"dismissal_encoded\", \"in_debt\"]]\n",
    "df_lstm_test = df_lstm_test[[\"case:concept:name\",\"type_of_event\", \"days_since_last\", \"days_since_start\", \"dismissal_encoded\", \"in_debt\"]]    \n",
    "\n",
    "classes = encoder.classes_\n",
    "classes = encoder.transform(classes) \n",
    "onehot_encoder = OneHotEncoder(sparse_output = False) # we want an array of arrays, not a matrix object\n",
    "onehot_encoder.fit(classes.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "8622cb531e0143db83879dfe79c8de17",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 73,
    "execution_start": 1711111945980,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#Splits a dataframe with test/train data into prefixes and suffices - if test, put True as 2nd parameter\n",
    "def prefixSuffix(df_lstm, test: bool = False): \n",
    "    all_events = df_lstm.groupby('case:concept:name')['type_of_event'].apply(list).tolist()\n",
    "    times = df_lstm.groupby('case:concept:name')['days_since_last'].apply(list).tolist()\n",
    "    \n",
    "    window = 3 # the minimum prefix length INCLUDING the <SOS> token\n",
    "    \n",
    "    #Pad sequences with SOS and EOS tokens\n",
    "    all_events = [[sos] + seq + [eos] for seq in all_events]\n",
    "    times = [[float(0)] + time + [float(0)] for time in times]\n",
    "    \n",
    "    prefixes = []\n",
    "    suffices = []\n",
    "    prefixes_time = []\n",
    "    suffices_time = []\n",
    "\n",
    "    for seq, time_seq in zip(all_events, times): \n",
    "        for i in range(len(seq) - window):\n",
    "            prefixes.append(seq[0:i+window])\n",
    "            suffices.append(seq[i+window] if not test else seq[i+window:])\n",
    "            prefixes_time.append(time_seq[0:i+window])\n",
    "            suffices_time.append(time_seq[i+window] if not test else time_seq[i+window:])\n",
    "    \n",
    "    prefixes = pad_sequences(prefixes, maxlen=max_length - 1, padding='post', value=no_next, dtype=int)\n",
    "    prefixes_time = pad_sequences(prefixes_time, maxlen=max_length - 1, padding='post', value=0, dtype=float)\n",
    "\n",
    "    #One-hot encode suffices for training data\n",
    "    if not test: \n",
    "        suffices = np.array(suffices)\n",
    "        suffices_time = np.array(suffices_time)\n",
    "        suffices = onehot_encoder.transform(suffices.reshape(-1,1))\n",
    "        \n",
    "    return prefixes, prefixes_time, suffices, suffices_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes, prefixes_time, suffices, suffices_time = prefixSuffix(df_lstm_train, False)\n",
    "\n",
    "# We are giving events and times separately for easier debugging, but the model is concatenating them into 1 input layer\n",
    "input_layer1 = Input(shape=(max_length - 1,))\n",
    "input_layer2 = Input(shape=(max_length - 1,))\n",
    "concatenated_inputs = Concatenate(axis=1)([input_layer1, input_layer2])\n",
    "concatenated_inputs = Reshape((2, max_length - 1))(concatenated_inputs)\n",
    "\n",
    "lstm_layer = LSTM(units=64, return_sequences=False)(concatenated_inputs)\n",
    "lstm_layer = Dropout(0.2)(lstm_layer) # A slight dropout rate, because otherwise it tends to overfit \n",
    "\n",
    "event_type_output = Dense(14, activation='softmax', name='event_type')(lstm_layer)\n",
    "timestamp_output = Dense(1, name='timestamp')(lstm_layer)  \n",
    "\n",
    "# Define model\n",
    "model = Model(inputs=[input_layer1, input_layer2], outputs=[event_type_output, timestamp_output])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss={'event_type': 'categorical_crossentropy', 'timestamp': 'mean_absolute_error'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/19\n",
      "\u001b[1m4333/4333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - loss: 0.6251\n",
      "Epoch 2/19\n",
      "\u001b[1m4333/4333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.3094\n",
      "Epoch 3/19\n",
      "\u001b[1m4333/4333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.2957\n",
      "Epoch 4/19\n",
      "\u001b[1m4333/4333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.2905\n",
      "Epoch 5/19\n",
      "\u001b[1m4333/4333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.2913\n",
      "Epoch 6/19\n",
      "\u001b[1m4333/4333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.2866\n",
      "Epoch 7/19\n",
      "\u001b[1m4333/4333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.2838\n",
      "Epoch 8/19\n",
      "\u001b[1m4333/4333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.2840\n",
      "Epoch 9/19\n",
      "\u001b[1m4333/4333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.2832\n",
      "Epoch 10/19\n",
      "\u001b[1m4333/4333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.2831\n",
      "Epoch 11/19\n",
      "\u001b[1m4333/4333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.2820\n",
      "Epoch 12/19\n",
      "\u001b[1m4333/4333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.2821\n",
      "Epoch 13/19\n",
      "\u001b[1m4333/4333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.2818\n",
      "Epoch 14/19\n",
      "\u001b[1m4333/4333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.2802\n",
      "Epoch 15/19\n",
      "\u001b[1m4333/4333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.2807\n",
      "Epoch 16/19\n",
      "\u001b[1m4333/4333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.2794\n",
      "Epoch 17/19\n",
      "\u001b[1m4333/4333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.2782\n",
      "Epoch 18/19\n",
      "\u001b[1m4333/4333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.2795\n",
      "Epoch 19/19\n",
      "\u001b[1m4333/4333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.2773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24006f17a10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([prefixes, prefixes_time], [suffices, suffices_time], epochs=19, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": "768c93532cb140d9b64b2cfa7d7435e8",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 106,
    "execution_start": 1711046173980,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "max_prediction = max_length - 2 # set a cut-off point to avoid getting into an endless loop, value can be changed \n",
    "def predictSuffix(prefix, prefix_time, suffix): \n",
    "    prediction = model.predict([prefix, prefix_time])\n",
    "    new_event = np.argmax(prediction[0], axis=1)[0]\n",
    "    new_timestamp = prediction[1][0][0]\n",
    "    \n",
    "    if (new_event == eos):\n",
    "        suffix.append([eos, 0.0]) #end of sequence token & padding time\n",
    "        return suffix \n",
    "\n",
    "    suffix.append([new_event, new_timestamp])\n",
    "    if np.isin(no_next, prefix[0]): #if there is still padding in the prefix\n",
    "        index = (np.where(prefix[0] == no_next)[0][0]) #find the padding\n",
    "        prefix[0, index] = new_event #replace it with the prediction\n",
    "        prefix_time[0][index] = new_timestamp \n",
    "        return predictSuffix(prefix, prefix_time, suffix)\n",
    "    else:\n",
    "        if len(suffix) > max_prediction: # suspiciosly long prediction, cut it short \n",
    "            suffix.append([eos, 0.0])\n",
    "            return suffix \n",
    "        else: \n",
    "            prefix.pop(0)\n",
    "            prefix.append(new_event)\n",
    "            prefix_time.pop(0)\n",
    "            prefix_time.append(new_timestamp)\n",
    "        return predictSuffix(prefix, prefix_time, suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "256a1c276f9f469b85b9d22eb7774e37",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1693,
    "execution_start": 1711112216098,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "prefixes, prefixes_time, suffices, suffices_time = prefixSuffix(df_lstm_test, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "89cb7b7476a243f19d96057167b2944d",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Example usage on a single trace from the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Predicted suffix: ['Insert Fine Notification' 'Add penalty' 'Send for Credit Collection'\n",
      " '<EOS>']\n",
      "Actual suffix: ['Insert Fine Notification' 'Add penalty' 'Payment' '<EOS>']\n",
      "The model is trained to predict how many days will have passed since the previous event:\n",
      "Predicted days: [[ 18.58207213]\n",
      " [ 61.88227559]\n",
      " [419.45317924]\n",
      " [  0.        ]]\n",
      "Actual days: [[ 11.]\n",
      " [ 60.]\n",
      " [101.]\n",
      " [  0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20221807\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:153: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "ind = random.randint(0, len(prefixes) - 1) \n",
    "input1 = prefixes[ind].copy().reshape(1, -1)\n",
    "input2 = prefixes_time[ind].copy().reshape(1, -1)\n",
    "ind = 29\n",
    "\n",
    "prediction = predictSuffix(input1, input2, []) \n",
    "event_prediction = [event[0] for event in prediction]\n",
    "time_prediction = [time[1] for time in prediction]\n",
    "actual_suffix = suffices[ind]\n",
    "actual_times = suffices_time[ind] \n",
    "\n",
    "print('Predicted suffix:', encoder.inverse_transform(np.array(event_prediction).reshape(-1, 1)))\n",
    "print('Actual suffix:', encoder.inverse_transform(actual_suffix))\n",
    "print('The model is trained to predict how many days will have passed since the previous event:')\n",
    "print('Predicted days:', scaler.inverse_transform(np.array(time_prediction).reshape(-1, 1)))\n",
    "print('Actual days:', scaler.inverse_transform(np.array(actual_times).reshape(-1, 1))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sample):\n",
    "    event_prediction = []\n",
    "    for i in range(sample[0], sample[1]):\n",
    "        suffix = []\n",
    "        result = predictSuffix(prefixes[i].reshape(1, -1), prefixes_time[i].reshape(1, -1), suffix)\n",
    "        event_prediction.append(result)\n",
    "    return event_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating on the entire test data takes very (very!) long, you can run on a sample by setting start and end index in an array and feeding it into evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_result = evaluate([0, len(prefixes)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suffix Prediction Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #events are label-encoded, instead of 1h encoded, so first we need to deal with that:\n",
    "# def convert_to_letters(sequence, mapping):\n",
    "#     return [mapping[element] for element in sequence]\n",
    "\n",
    "# int_to_letter = {i: chr(65 + i) for i in range(len(encoder.classes_))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 130.88949434431146\n",
      "DL Distance: 0.1336055564607134\n",
      "DLS: 0.8663944435392866\n"
     ]
    }
   ],
   "source": [
    "# import textdistance\n",
    "# import statistics\n",
    "# events_predicted = [[event[0] for event in suffix] for suffix in test_result] \n",
    "# times_predicted = [[event[1] for event in suffix] for suffix in test_result]\n",
    "# times_predicted = pad_sequences(times_predicted, maxlen=14, value = 0, padding='post', dtype = float)\n",
    "# suffices_time = pad_sequences(suffices_time, maxlen=14, value = 0, padding='post', dtype = float)\n",
    "\n",
    "# #MAE\n",
    "# decoded_prediction = scaler.inverse_transform(times_predicted)\n",
    "# decoded_real = scaler.inverse_transform(suffices_time) \n",
    "\n",
    "# total_times_predicted = np.sum(decoded_prediction, axis=1) #predicted times until EOS\n",
    "# total_times_real = np.sum(decoded_real, axis=1) #real times until EOS\n",
    "# mae = mean_absolute_error(total_times_real, total_times_predicted) \n",
    "# print('MAE:', mae)\n",
    "\n",
    "# #Represent each suffix as a string of unique letters \n",
    "# suffices_letters = [convert_to_letters(seq, int_to_letter) for seq in suffices]\n",
    "# events_predicted_letters = [convert_to_letters(seq, int_to_letter) for seq in events_predicted]\n",
    "\n",
    "# #Damerau-Levenstein (distance (not similarity), normalized)\n",
    "# distances = []\n",
    "# for actual, predicted in zip(suffices_letters, events_predicted_letters):\n",
    "#     actual_str = \"\".join(actual)\n",
    "#     predicted_str = \"\".join(predicted)\n",
    "\n",
    "#     distance = textdistance.damerau_levenshtein.normalized_distance(actual_str, predicted_str)\n",
    "#     distances.append(distance)\n",
    "    \n",
    "# print('DL Distance:', np.mean(distances))\n",
    "# # #We take the mean and compute the similarity by subtracting it from 1\n",
    "# print('DLS:', 1 - np.mean(distances))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9f75dafc3a824573a1653b4926665abb",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": []
   },
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "5120f6fcf2624e08b4076d3041bb3dc0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 28,
    "execution_start": 1711016643584,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "df.to_csv('FinalTool23.csv')"
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "feb4f10dbd244717a7f8bdcd50bcab9f",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
